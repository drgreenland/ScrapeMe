# Iteration 1 - 2026-02-05 16:48:41

## Goal
Build a complete Python web scraper to monitor Australian newspapers for Perth Bears Rugby League news, with SQLite storage and a local web interface.

## Summary
Implemented the full Perth Bears News Scraper from scratch, including 8 news source scrapers, a SQLite database, and a Flask-based web viewer with filtering and annotation features.

## Changes Made

### Code Changes
- Created project structure with `scraper/` and `viewer/` directories
- Implemented `BaseScraper` abstract class with rate limiting, retry logic, and keyword matching
- Created 8 source-specific scrapers: NRL.com, The Roar, The West Australian, PerthNow, Fox Sports, SMH, The Age, CODE Sports
- Built SQLite database module with CRUD operations and deduplication
- Implemented Flask web viewer with:
  - Article listing with pagination
  - Filtering by source, relevance, read status
  - Read/unread tracking
  - Article detail view
  - Notes feature for annotations
- Added mobile-responsive CSS styling

### Configuration Changes
- Created `config.py` with keywords, sources, and settings
- Set web viewer to port 5050 (avoiding macOS AirPlay on 5000)
- Added "NRL" as temporary broad keyword for testing

### Documentation Changes
- Created `README.md` with project overview
- Created `SETUP_GUIDE.md` with detailed setup instructions
- Added `setup_cron.sh` for scheduled scraping

## Files Modified
```
27 files changed, 3239 insertions(+)
 .claude/context-meta.json
 .claude/context.md
 .gitignore
 README.md
 SETUP_GUIDE.md
 config.py
 requirements.txt
 scraper/__init__.py
 scraper/database.py
 scraper/main.py
 scraper/sources/__init__.py
 scraper/sources/base.py
 scraper/sources/codesports.py
 scraper/sources/foxsports.py
 scraper/sources/nrl_official.py
 scraper/sources/perthnow.py
 scraper/sources/smh.py
 scraper/sources/theage.py
 scraper/sources/theroar.py
 scraper/sources/thewest.py
 setup_cron.sh
 viewer/__init__.py
 viewer/server.py
 viewer/static/style.css
 viewer/templates/article.html
 viewer/templates/index.html
```

## Git Context

**Branch:** main

**Commits:**
```
9067704 Initial commit: Perth Bears News Scraper
```

**Status:**
```
Clean - all files committed
```

## Decisions & Learnings

### Architectural Decisions
- **Abstract base class pattern** for scrapers - allows easy addition of new sources
- **SQLite over JSON** - better querying, deduplication, and scalability
- **Flask over built-in http.server** - needed template rendering and routing
- **Port 5050** - macOS Monterey+ uses port 5000 for AirPlay Receiver
- **Rate limiting 3-5 seconds** - respectful scraping to avoid blocks

### Problems Encountered
1. **Port 5000 blocked** - macOS AirPlay was returning 403 errors. Fixed by changing to port 5050.
2. **No articles initially** - Keywords were too specific ("Perth Bears"). Added broader "NRL" keyword for testing.
3. **Some sources failing** - Fox Sports and CODE Sports have redirect issues; The West/SMH/The Age return 0 URLs due to selector mismatches.

### Key Learnings
- Perth Bears news coverage is sparse (team doesn't start until 2027)
- News Corp sites (Fox Sports, CODE Sports) have aggressive anti-scraping redirects
- Nine network sites (SMH, The Age) use JavaScript-heavy rendering
- Always check what's using common ports on macOS

## Next Steps
- Fix CSS selectors for The West Australian, SMH, The Age
- Investigate Fox Sports/CODE Sports redirect issues
- Remove temporary "NRL" keyword once Perth Bears news increases
- Consider RSS feeds as alternative data source
- Test CRON scheduling over multiple days
- Implement database-backed notes storage (currently copy/paste only)

## Notes
- Project pushed to https://github.com/drgreenland/ScrapeMe.git
- Virtual environment not included in repo (recreate with `python3 -m venv venv`)
- Database and logs excluded via .gitignore
